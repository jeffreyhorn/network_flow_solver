# Changelog

All notable changes to this project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- **Automatic pricing strategy selection for grid-on-torus structures** (`simplex.py`)
  - **Feature**: Auto-detects grid-on-torus network structures and switches to Dantzig pricing
  - **Performance**: GOTO instances now solve in ~14s (previously timed out at 300s+ with Devex)
  - **Implementation**:
    - `_select_pricing_strategy()`: Detects GOTO patterns based on structural heuristics
    - Heuristics: ≤4 supply/demand nodes, >98% transshipment, regular grid connectivity
    - Preserves user-specified pricing strategy when explicitly set
  - **Impact**: Enables previously unsolvable GOTO instances without affecting other problem types
  - **Diagnostic tool**: `benchmarks/scripts/diagnose_goto.py` for analyzing convergence issues
- **Benchmark comparison tool** (`benchmarks/scripts/compare_configurations.py`)
  - **Feature**: Compare solver performance across different configurations
  - **Capabilities**:
    - Run multiple instances with different solver options (pricing strategies, scaling, etc.)
    - Generate comparison tables showing per-instance and aggregate statistics
    - Export results to JSON for further analysis
  - **Usage**: `python benchmarks/scripts/compare_configurations.py --instances <files> --configs <configs>`
  - **Configurations**: default, dantzig, devex, no_scaling
- **Optional Numba JIT compilation for Forrest-Tomlin operations** (`forrest_tomlin.py`, `basis.py`, `data.py`, `simplex.py`)
  - **Feature**: Optional JIT (Just-In-Time) compilation for performance-critical Forrest-Tomlin update loops
  - **Installation**: `pip install 'network-flow-solver[jit]'` or `pip install numba>=0.58.0`
  - **Performance**: Targets the primary computational bottleneck (Forrest-Tomlin solves: 49.7% of baseline runtime)
  - **Implementation**:
    - `_apply_ft_updates_jit()`: JIT-compiled update application using Numba's @njit decorator
    - `_apply_ft_updates_python()`: Pure Python fallback when Numba unavailable
    - Automatic detection: uses JIT if Numba installed, gracefully falls back to Python
    - Converts FTUpdate list to NumPy arrays (pivots, ys, thetas) for efficient batch processing
  - **Configuration**:
    - `SolverOptions(use_jit=True)` - Enable JIT compilation (default, requires Numba)
    - `SolverOptions(use_jit=False)` - Disable JIT compilation (pure Python)
    - Automatically falls back to Python if Numba not installed (no errors)
  - **Benchmark**: `benchmarks/benchmark_jit_compilation.py`
  - **Note**: Performance impact varies by problem size; best for large problems with many FT updates
  - Implements Project 6 from optimization roadmap
- **Vectorized residual calculations** (`simplex.py`, `simplex_pricing.py`, `specialized_pivots.py`)
  - **Feature**: Pre-computed residual arrays cached and updated on flow changes
  - **Performance improvements**:
    - Eliminates ~750,000 function calls per solve on large problems
    - Array lookups replace method calls for forward/backward residuals
    - Performance improvement scales with problem size
  - **Implementation**:
    - `self.forward_residuals` and `self.backward_residuals` cached in `_build_vectorized_arrays()`
    - Updated in `_sync_vectorized_arrays()` after flow changes
    - Replaced `arc.forward_residual()` and `arc.backward_residual()` with array lookups
    - Applied in ratio test, pricing strategies, and specialized pivots
  - **Benefit**: O(1) array lookups vs Python method call overhead
  - Completes Project 4 from optimization roadmap
- **Deferred Devex weight updates (loop-based pricing optimization)** (`simplex_pricing.py`)
  - **Feature**: Loop-based Devex pricing now defers weight updates until after arc selection
  - **Performance improvements**:
    - **97.5% reduction** in `_update_weight` calls (1,375 → 47 per solve)
    - **94% reduction** in `project_column` calls (1,422 → 81 per solve)
    - **37% faster** loop-based pricing (0.390s → 0.244s on medium problems)
  - **Implementation**: Update weight only for the selected entering arc, not all examined candidates
  - **Benefit**: Significantly improves loop-based fallback performance (when `use_vectorized_pricing=False`)
  - Note: Vectorized pricing (default) already had this optimization built-in
  - Completes Project 3 from optimization roadmap
- **Vectorized pricing operations (enabled by default)** (`simplex.py`, `simplex_pricing.py`)
  - **Feature**: Devex pricing uses vectorized NumPy array operations by default for dramatically improved performance
  - **Performance improvements**:
    - Small problems (300 arcs): **162% speedup** (2.6x faster)
    - Medium problems (600 arcs): **92% speedup** (1.9x faster)
    - Average improvement: **127% speedup** (2.3x faster)
  - **Anti-cycling mechanism**: Minimal exclusion of last degenerate arc prevents infinite loops on zero-cost arcs while preserving optimal solutions
  - Significantly exceeds 10% target from optimization roadmap (Project 2: Vectorize Pricing)
  - **Implementation**:
    - `_build_vectorized_arrays()`: Creates NumPy arrays mirroring ArcState list (costs, tails, heads, capacities, flows, tree status, node potentials)
    - `_sync_vectorized_arrays()`: Syncs arrays when arcs are modified (artificial arcs added, flows updated)
    - `_compute_reduced_costs_vectorized()`: Computes all reduced costs using vectorized operations
    - `_compute_residuals_vectorized()`: Computes forward/backward residuals efficiently
    - `_select_entering_arc_vectorized()`: Selects best entering arc using NumPy masked arrays for eligibility checks and merit computation
    - Devex pricing automatically uses vectorization when solver instance is available
  - **Configuration**:
    - **Enabled by default**: `SolverOptions(use_vectorized_pricing=True)` (recommended)
    - Can be disabled for debugging: `use_vectorized_pricing=False`
    - Only applies to Devex pricing strategy (Dantzig is always loop-based)
  - **Benefits**:
    - Replaces Python loops with batch operations on NumPy arrays
    - Particularly effective for problems with many arcs where pricing is a bottleneck
    - Stable and production-ready
    - Often requires fewer iterations than loop-based version to reach optimality
  - **Integration**:
    - Modified `PricingStrategy.select_entering_arc()` to accept optional solver parameter
    - `DevexPricing._select_entering_arc_vectorized()` leverages solver's vectorized infrastructure
    - Called automatically from `NetworkSimplex._find_entering_arc()` when enabled
  - **Benchmark script**: `benchmarks/benchmark_vectorized_pricing.py` demonstrates performance improvements
  - **Documentation**: Updated README.md and docs/api.md with enabled-by-default status and performance metrics
  - All core optimality tests passing with vectorization **enabled** (default)

- **Projection cache for basis solves** (`basis.py`, `data.py`)
  - **Feature**: Optimized cache for basis projection results provides 10-14% speedup on medium/large problems
  - **Performance**:
    - Medium problems (70+ nodes): **1.10-1.14x speedup**
    - Large problems (130+ nodes): approaching neutral to slight speedup
    - Small problems (< 50 nodes): slight overhead (5%), can disable with `projection_cache_size=0`
  - **Implementation**:
    - Simple dict-based cache (not LRU) for minimal overhead
    - Cache automatically cleared when basis changes (invalidation strategy)
    - Returns copy of cached arrays to prevent corruption
    - 50% reduction in array copying vs initial implementation
  - **Configuration**: `SolverOptions(projection_cache_size=100)` (enabled by default)
  - **Memory usage**: ~800 bytes per cached projection (negligible)
  - **Optimization details**: See `docs/project_plans/CACHE_OPTIMIZATION_RESULTS.md` for analysis
  - **Documentation**: Updated docs/api.md, docs/examples.md with cache configuration options
- **Preprocessing result translation to original problem structure** (`preprocessing.py`)
  - **Feature**: Solutions from preprocessed problems are automatically translated back to original problem structure
  - **Functionality**:
    - `preprocess_and_solve()` now returns flows and duals for the **original** problem
    - All original arcs have flow values (including removed/merged arcs)
    - All original nodes have dual values (including removed nodes)
  - **Translation logic**:
    - Removed arcs → assigned zero flow
    - Redundant arcs (merged) → flows distributed proportionally by capacity
    - Series arcs (merged) → all arcs in series carry the same flow
    - Removed nodes → duals computed from adjacent preserved arcs
    - Preserved arcs/nodes → flows/duals copied directly from preprocessed solution
  - **Benefits**:
    - Transparent preprocessing - solution always corresponds to original problem
    - No need to manually track arc/node mappings
    - Can use preprocessing without changing downstream code
    - Enables sensitivity analysis on removed nodes
  - **Performance**: O(n) translation overhead, negligible compared to solve time
  - **API**: `translate_result()` function available for manual translation if needed
  - **Documentation**: Updated README.md, docs/api.md, docs/examples.md, and preprocessing_example.py
  - **Tests**: 33 preprocessing tests including result translation validation

### Changed
- **Refactor: Extracted adaptive tuning into separate module** (`simplex_adaptive.py`)
  - **Motivation**: Continue improving maintainability of NetworkSimplex class by extracting runtime parameter adaptation logic
  - **Changes**:
    - Created `simplex_adaptive.py` with `AdaptiveTuner` class
    - Moved block size computation and adaptation logic (degeneracy-based)
    - Moved Forrest-Tomlin update limit adjustment (condition-number-based)
    - Moved pivot statistics tracking (degenerate vs non-degenerate pivots)
    - Added backward compatibility properties to NetworkSimplex (`block_size`, `auto_tune_block_size`, `current_ft_limit`)
    - Removed ~105 lines of adaptive tuning code from NetworkSimplex
    - Added section headers to simplex.py for improved code organization:
      - Problem Setup and Initialization
      - Basis Management and Warm-Start
      - Pricing Strategy Integration
      - Simplex Iterations and Phase Management
      - Pivot Operations
      - Cost Perturbation and Degeneracy Handling
      - Main Solve Method
      - Utility Methods
  - **Benefits**:
    - Clearer separation: Adaptive tuning logic isolated in dedicated module
    - Easier testing: Can unit test tuning heuristics independently
    - Better organization: Section headers make NetworkSimplex easier to navigate
  - **API Compatibility**: Fully backward compatible via property delegation - all 444+ unit tests pass
  - **Status**: Completed Option A-Lite approach - stopping modularization here and focusing on internal organization

- **Refactor: Extracted pricing strategies into separate module** (`simplex_pricing.py`)
  - **Motivation**: Improve maintainability and extensibility of the 1490-line NetworkSimplex class
  - **Changes**:
    - Created `simplex_pricing.py` with `PricingStrategy` abstract base class
    - Implemented `DantzigPricing` (most negative reduced cost)
    - Implemented `DevexPricing` (steepest edge approximation with block search)
    - NetworkSimplex now uses composition pattern with pricing strategy delegation
    - Removed ~120 lines of pricing code from NetworkSimplex
  - **Benefits**:
    - Single Responsibility: Each pricing strategy is self-contained
    - Open/Closed: Easy to add new pricing strategies without modifying NetworkSimplex
    - Testability: Pricing strategies can be unit tested independently
    - Readability: Clearer separation of concerns
  - **API Compatibility**: Fully backward compatible - all 444 unit tests pass without modification
  - **Future Work**: Continue modularization with basis management, pivot operations, and adaptive tuning

### Fixed
- **CRITICAL: Pivot theta computation bug causing flow conservation violations** (`simplex.py:951-995`)
  - **Root cause**: The theta computation loop was incorrectly skipping the entering arc's capacity constraint
  - **Impact**: Pivots could assign flow exceeding the entering arc's capacity, causing flow to "disappear" and violating conservation
  - **Symptoms**: Solver would return invalid solutions with violated flow conservation, or incorrectly report feasible problems as infeasible
  - **Fix**: Removed the `if idx == arc_idx: continue` check that was skipping the entering arc in theta computation
  - **Result**: All pivots now correctly maintain flow conservation throughout the algorithm
  - **Tests fixed**: 8 previously failing/xfail tests now pass, including:
    - `test_phase1_early_termination_parallel_paths` - now finds optimal solution (cost=45)
    - `test_tight_tolerance_solve` - high precision solve now works correctly
    - `test_flow_aggregation_with_duplicate_keys` - duplicate arc handling fixed
    - `test_undirected_multiple_edges` - parallel edges in undirected graphs
    - `test_extract_path_with_branching` - path extraction with multiple paths
    - `test_compute_bottleneck_arcs_sorting` - bottleneck analysis sorting
  - **Investigation details**: See `tests/unit/test_phase1_early_termination.py` for detailed documentation

- **Phase 1 flow conservation validation** (`simplex.py:1275-1318`)
  - Added flow conservation check after Phase 1 completes (for all cases, not just warm-start)
  - Defensive check that detected the pivot bug before it was fixed
  - Prevents solver from returning invalid "optimal" solutions
  - Returns "infeasible" status when conservation violations are detected

- **Warm-start with identical problem** (`simplex.py:420-445`)
  - Removed outdated TODO comment and docstring about warm-start failing on identical problems
  - This issue was inadvertently resolved by the pivot bug fix (flow conservation is now maintained)
  - Verified: warm-starting with a basis from an identical problem now works correctly

- **Warm-start with minimal basis creating disconnected components** (`test_warm_start.py:652-691`)
  - Fixed `test_warm_start_single_arc_basis_creates_components` which was previously xfailed
  - The test was failing due to the pivot bug, not due to minimal basis handling
  - Corrected expected objective value from 30.0 to 45.0 (optimal path: a→b→c→d at 3.0/unit)
  - All 22 warm-start tests now pass with no xfails

- **Iteration limit status misreported when optimal solution found at exact budget** (`simplex.py:1353-1378`)
  - **Root cause**: Status computation only checked if `total_iterations >= max_iterations` without verifying optimality
  - **Impact**: Solver incorrectly reported `status="iteration_limit"` with a warning when the last allowed pivot found the optimal solution
  - **Fix**: After hitting iteration limit, check for negative reduced cost arcs via `_find_entering_arc()`. If none exist, solution is optimal
  - **Result**: Solver now correctly reports `status="optimal"` when optimum is found at exact iteration budget
  - **Test added**: `test_optimal_at_exact_iteration_limit` regression test in `test_solver_options.py`

### Added
- **Jupyter notebook tutorial for visualization utilities** (`tutorials/visualization_tutorial.ipynb`)
  - Comprehensive tutorial demonstrating all visualization features
  - Six interactive examples covering different network types
  - Shows network structure visualization, flow solutions, and bottleneck analysis
  - Demonstrates multiple layout algorithms and customization options
  - Includes examples of saving figures for reports and presentations

- **Visualization utilities for network graphs and flow solutions**
  - **Three visualization functions** (`visualization.py`) for interactive analysis:
    - **visualize_network()**: Network structure with nodes, arcs, costs, capacities
    - **visualize_flows()**: Flow solution with bottleneck highlighting
    - **visualize_bottlenecks()**: Focused bottleneck analysis with utilization heatmap
  - **Network structure visualization**:
    - Automatic node categorization (sources=green, sinks=red, transshipment=blue)
    - Arc labels showing costs and capacities
    - Supply/demand values displayed on nodes
    - Multiple layout algorithms (spring, circular, kamada_kawai, planar)
  - **Flow solution visualization**:
    - Flow values displayed on arcs
    - Arc thickness proportional to flow magnitude
    - Bottleneck highlighting (arcs ≥ threshold shown in red)
    - Utilization percentages displayed
    - Option to hide zero flows for cleaner visualization
    - Statistics box showing objective, status, iterations
  - **Bottleneck analysis visualization**:
    - Utilization heatmap with color gradient (red=high, yellow=medium, green=low)
    - Only shows arcs above utilization threshold
    - Displays utilization percentage and slack capacity
    - Color bar for utilization scale
    - Statistics showing bottleneck count and average utilization
  - **Customization options**:
    - Layout algorithm selection
    - Figure size, node size, font size
    - Custom titles
    - Bottleneck threshold adjustment
    - Show/hide zero flows
  - **Optional dependencies**:
    - New `visualization` dependency group in pyproject.toml
    - Requires matplotlib>=3.5.0 and networkx>=3.0
    - Install with: `pip install 'network_solver[visualization]'`
    - Graceful ImportError when dependencies missing
  - **Comprehensive test suite** (`tests/unit/test_visualization.py`):
    - 26 tests covering all visualization functions
    - Tests for customization options and layouts
    - Error handling and edge cases
    - Integration tests with different problem types
    - All tests passing
  - **Example demonstration** (`examples/visualization_example.py`):
    - 6 complete examples showing all features
    - Basic network, flows, bottleneck highlighting
    - Transportation problem (3×3)
    - Multi-stage supply chain with transshipment
    - Bottleneck analysis with heatmap
    - Generates 8 PNG files with detailed visualizations
  - **Benefits**:
    - Visual problem understanding (structure, complexity)
    - Flow pattern analysis (routing, utilization)
    - Bottleneck identification (capacity constraints)
    - Publication-quality figures for reports
    - Interactive problem exploration
  - **Integration**:
    - Exported from main `network_solver` module
    - Works with all problem types (directed/undirected)
    - Compatible with all solver features
    - Returns matplotlib Figure objects for further customization

### Added
- **Problem preprocessing for reduced problem size and faster solving**
  - **Four optimization techniques** (`preprocessing.py`) to simplify problems before solving:
    - **Remove redundant arcs**: Parallel arcs with identical costs merged (capacities combined)
    - **Detect disconnected components**: BFS-based connectivity analysis warns of infeasibility
    - **Simplify series arcs**: Merge consecutive arcs through zero-supply transshipment nodes
    - **Remove zero-supply nodes**: Eliminate transshipment nodes with single incident arc
  - **PreprocessingResult dataclass** tracks optimization statistics:
    - `removed_arcs`, `removed_nodes`, `merged_arcs`, `redundant_arcs` counters
    - `disconnected_components` count for connectivity analysis
    - `preprocessing_time_ms` for performance tracking
    - `optimizations` dict with detailed breakdown by optimization type
  - **Series arc simplification algorithm** (`_simplify_series_arcs()`):
    - Iterative greedy approach merges transshipment nodes safely
    - Handles chains of consecutive transshipment nodes correctly
    - Avoids creating arcs referencing deleted nodes via incremental selection
    - Combines arc costs (sum), capacities (min), and lower bounds (max)
  - **Public API functions**:
    - `preprocess_problem()`: Apply optimizations with configurable flags
    - `preprocess_and_solve()`: Convenience function for preprocessing + solving
    - `PreprocessingResult`: Export preprocessing statistics
  - **Configuration options** in `preprocess_problem()`:
    - `remove_redundant: bool` - Merge parallel arcs (default: True)
    - `detect_disconnected: bool` - Connectivity analysis (default: True)
    - `simplify_series: bool` - Series arc merging (default: True)
    - `remove_zero_supply: bool` - Single-arc node removal (default: True)
  - **Structured logging** at INFO level:
    - Reports optimization counts when changes made
    - Warnings for disconnected components (potential infeasibility)
    - Summary statistics with time/arc/node reductions
  - **Comprehensive test suite** (`tests/unit/test_preprocessing.py`):
    - 24 tests covering all optimizations and edge cases
    - Tests for redundant arcs, disconnected components, series arcs, zero-supply nodes
    - Integration tests verifying preprocessing preserves solutions
    - Statistics tracking and selective optimization tests
  - **Example demonstration** (`examples/preprocessing_example.py`):
    - 6 scenarios showing all preprocessing features
    - Redundant arc removal, series simplification, component detection
    - Combined preprocessing on large problem (20 nodes, 24 arcs)
    - Performance comparison: 1.45x speedup with preprocessing
    - Selective preprocessing (enable/disable specific optimizations)
  - **Benefits**:
    - Problem size reduction: typical 20-50% fewer arcs/nodes
    - Faster solve times: 1.2x-2x speedup for large problems
    - Semantics preserved: optimal solutions identical to original
    - Automatic application: enabled by default in preprocessing
  - **Integration**:
    - Exported from main `network_solver` module
    - Works with all problem types (directed/undirected)
    - Compatible with automatic scaling and adaptive refactorization
    - Solutions map back to original problem automatically
  - All 411 tests passing with preprocessing implementation

### Added
- **Adaptive basis refactorization for improved numerical stability**
  - **Condition number monitoring** (`basis.py`) tracks numerical stability during solve:
    - `estimate_condition_number()` method in TreeBasis class
    - Fast 1-norm approximation: `cond(A) ≈ ||A||_1 * ||A^-1||_1`
    - Returns None when basis matrix not available
    - Values > 1e12 typically indicate ill-conditioning
  - **Adaptive refactorization logic** (`simplex.py`) responds to numerical issues:
    - Tracks `condition_number_history` during solve (list of float)
    - Monitors condition number after each pivot operation
    - Triggers rebuild when condition number exceeds threshold
    - `_adjust_ft_limit()` method adapts refactorization frequency dynamically
    - `current_ft_limit` adjusted based on observed conditioning behavior
  - **Adaptive adjustment strategy**:
    - Very high condition (>10x threshold): reduce limit by 50% (more frequent rebuilds)
    - Moderately high (>threshold): reduce limit by 20% (gradual increase in frequency)
    - Low/good conditioning: increase limit by 10% (fewer rebuilds for efficiency)
    - Always respects configured `adaptive_ft_min` and `adaptive_ft_max` bounds
  - **Configuration options** (`data.py` SolverOptions):
    - `adaptive_refactorization: bool` - Enable/disable adaptive mode (default: True)
    - `condition_number_threshold: float` - Trigger threshold (default: 1e12)
    - `adaptive_ft_min: int` - Minimum refactorization limit (default: 20)
    - `adaptive_ft_max: int` - Maximum refactorization limit (default: 200)
    - `ft_update_limit: int` - Starting limit or fixed limit if adaptive disabled (default: 64)
    - Comprehensive validation with helpful error messages
  - **Integration into solver**:
    - Enabled by default for all solves (adaptive_refactorization=True)
    - Works in combination with automatic problem scaling
    - Dual triggering: condition number OR update count
    - Structured logging at DEBUG level for rebuild events with metrics
    - Zero performance impact for well-conditioned problems
  - **Comprehensive test suite** (`tests/unit/test_adaptive_refactorization.py`):
    - 17 tests covering configuration, validation, estimation, behavior, stability, edge cases
    - Tests for default options and customization
    - Validation tests for invalid thresholds and bounds
    - Condition number estimation with valid basis and None fallback
    - Behavior tests for enabled/disabled modes, history tracking, limit adjustment
    - Stability tests comparing adaptive vs fixed strategies
    - Edge cases: single arc, zero costs, extreme thresholds, tight bounds
    - All tests passing with comprehensive coverage
  - **Example and documentation**:
    - `examples/adaptive_refactorization_example.py`: 6 scenarios demonstrating feature
    - Shows default settings, custom configuration, ill-conditioned problems
    - Compares adaptive vs fixed refactorization strategies
    - Includes usage guidelines and tuning recommendations
    - README.md: New "Adaptive Basis Refactorization" section with complete examples

### Added
- **Automatic problem scaling for numerical stability**
  - **Scaling detection** (`scaling.py`) automatically detects problems with wide value ranges:
    - Triggers when costs, capacities, or supplies differ by >6 orders of magnitude (threshold: 1e6)
    - Analyzes cross-category ranges (e.g., tiny costs vs. huge capacities)
    - Ignores infinite capacities and zero values in range calculations
  - **Geometric mean-based scaling factors**:
    - `ScalingFactors` dataclass stores cost_scale, capacity_scale, supply_scale, and enabled flag
    - `compute_scaling_factors()` uses geometric mean to normalize each category to ~1.0
    - Brings values into target range [0.1, 100] for 3 orders of magnitude buffer
  - **Automatic scaling transformations**:
    - `scale_problem()` creates scaled copy: costs × cost_scale, capacities × capacity_scale, supplies × supply_scale
    - `unscale_solution()` reverses scaling: flows ÷ supply_scale, objective ÷ (cost_scale × supply_scale)
    - Preserves problem structure and feasibility
  - **Integrated into NetworkSimplex solver**:
    - Enabled by default via `SolverOptions(auto_scale=True)`
    - Scaling applied in `__init__()` before basis construction
    - Solution unscaled in `solve()` before returning FlowResult
    - Logging at INFO level when scaling applied with factor values
  - **Public API exports**:
    - `should_scale_problem()` for manual scaling detection
    - `compute_scaling_factors()` for factor computation
    - `ScalingFactors` dataclass
    - `SolverOptions.auto_scale` configuration (default: True)
  - **Comprehensive test suite** (`tests/unit/test_scaling.py`):
    - 21 tests covering detection, factor computation, transformations, integration, and edge cases
    - Tests for wide cost/capacity/supply ranges and cross-category detection
    - Tests for scaling with infinite capacities and lower bounds
    - Integration tests verify solver produces correct results with/without scaling
  - **Example and documentation**:
    - `examples/automatic_scaling_example.py`: Demonstrates scaling with extreme value ranges
    - Shows scaling factors, compares scaled vs unscaled solving
    - Includes transportation problem with micro-costs and macro-supplies

### Fixed
- **Warm-start infeasibility detection**: Fixed critical bug where warm-start with capacity-reduced arcs would return invalid solutions
  - Added flow conservation validation after Phase 1 for warm-start cases
  - Detects when warm-start basis leads to infeasible state with zero artificial flow but violated flow conservation
  - Previously, solver could return "optimal" status with flows violating conservation constraints
  - Test `test_warm_start_capacity_decrease_infeasible_flow` now passes (previously marked as xfail)
  - Also validates basis arc flows against current capacity bounds during warm-start application
  - Improved `_recompute_tree_flows()` to detect capacity violations and fall back to cold start

### Added
- **Network specializations with automatic detection and optimized pivot strategies**
  - **Detection system** (`specializations.py`) with comprehensive problem classification:
    - `NetworkType` enum: TRANSPORTATION, ASSIGNMENT, BIPARTITE_MATCHING, MAX_FLOW, SHORTEST_PATH, GENERAL
    - `NetworkStructure` dataclass containing detected properties (node types, bipartite partitions, balance, bounds)
    - `analyze_network_structure()` function using BFS 2-coloring for bipartite detection
    - Categorizes nodes as sources (supply > 0), sinks (supply < 0), or transshipment (supply = 0)
    - Detection priority: Transportation → Assignment → Bipartite Matching → Shortest Path → Max Flow → General
  - **Specialized pivot strategies** (`specialized_pivots.py`) for optimized arc selection:
    - `TransportationPivotStrategy`: Row-scan pricing exploiting bipartite structure
    - `AssignmentPivotStrategy`: Min-cost selection for n×n unit-value problems
    - `BipartiteMatchingPivotStrategy`: Augmenting path methods for non-assignment bipartite matching
    - `MaxFlowPivotStrategy`: Capacity-based selection prioritizing high-capacity arcs for larger flow increments
    - `ShortestPathPivotStrategy`: Distance-label-based selection (Dijkstra-like) with path extension guidance
    - `select_pivot_strategy()`: Automatic strategy selection based on network type
    - All 5 specialized problem types now have optimized pivot strategies
  - **Integrated into NetworkSimplex solver**:
    - Automatic detection during solver initialization
    - Specialized pivot strategies tried first, fallback to standard pricing
    - Logging at INFO level: "Detected network type" and "Using specialized pivot strategy"
    - Zero performance impact when specialized structure not detected
  - **Public API exports**:
    - `NetworkType` enum exported from main module
    - `analyze_network_structure()` for manual structure analysis
    - `get_specialization_info()` for human-readable descriptions
  - **Comprehensive test suite** (`tests/unit/test_specializations.py`):
    - 13 tests covering all problem types and detection logic
    - Tests for bipartite graph detection (BFS 2-coloring algorithm)
    - Tests for structure property analysis (sources, sinks, transshipment nodes)
    - Tests for specialization info generation
  - **Documentation**:
    - README.md: New "Network Specializations and Optimized Pivots" section with complete example
    - Benefits, API functions, and detection algorithm explanation
- **Block size auto-tuning with hybrid approach**
  - `SolverOptions.block_size` now accepts `int`, `"auto"`, or `None`
  - `None` and `"auto"` enable automatic tuning (new default behavior)
  - Explicit `int` value disables auto-tuning (fixed block size)
  - **Static heuristic** selects initial block size based on problem size:
    - Very small (<100 arcs): `num_arcs // 4`
    - Small (100-1000 arcs): `num_arcs // 4`
    - Medium (1000-10000 arcs): `num_arcs // 8`
    - Large (>10000 arcs): `num_arcs // 16`
  - **Runtime adaptation** adjusts block size every 50 iterations based on performance:
    - High degenerate pivot ratio (>30%): increase block size by 1.5x (explore wider)
    - Low degenerate pivot ratio (<10%): decrease block size by 0.75x (focused search)
    - Clamped to range `[10, num_arcs]`
  - Structured logging at DEBUG level for adaptation events with metrics
  - New test suite with 7 comprehensive tests for auto-tuning (22 total solver options tests)

### Changed
- **Default block_size behavior is now auto-tuning**
  - Previously: `None` defaulted to `num_arcs // 8` (static)
  - Now: `None` enables auto-tuning with problem-size-based initial value and runtime adaptation
  - Users can still specify explicit `int` for fixed block size (backward compatible)
- **Updated documentation for auto-tuning**
  - SolverOptions docstring with auto-tuning examples
  - README section explaining static heuristic and runtime adaptation
  - Performance tuning guidance updated

### Fixed
- **Warm-start implementation fully functional** - Fixed critical bugs preventing warm-start from working correctly
  - Fixed Union-Find component detection to correctly identify connected components in basis
  - Made `_initialize_tree()` idempotent to prevent duplicate artificial arcs on fallback
  - Fixed phase cost application after failed warm-start (was skipping initialization)
  - Fixed early validation in `_apply_warm_start_basis()` to check basis before modifying state
  - Reimplemented `_recompute_tree_flows()` using proper post-order tree traversal
  - All 16 warm-start tests now passing (previously marked as xfail)

### Changed (Warm-Start)
- **Removed experimental status from warm-start feature**
  - Removed xfail markers from all warm-start tests
  - Updated README.md to remove experimental warnings
  - Warm-start is now production-ready and fully supported

### Known Limitations
- **Warm-start edge case with identical problems**
  - When rebuilding the exact same problem (identical structure and parameters) and applying warm-start with its own basis, the solver may become infeasible with objective=0
  - This edge case was discovered during testing but could not be fixed without breaking existing tests
  - Workaround: Use cold start (default) when re-solving identical problems, or make a small parameter change
  - Warm-start works correctly for similar problems with moderate changes (supply/demand, costs, capacities)
  - See GitHub issue for tracking and technical details

## [0.1.0] - 2024-10-17

### Added
- Initial release with proper Python packaging
- `pyproject.toml` for modern Python packaging (PEP 621 compliant)
- Package versioning (`__version__ = "0.1.0"`)
- `py.typed` marker for type checking support
- `LICENSE` file (MIT License)
- `INSTALL.md` with detailed installation instructions
- `scripts/verify_install.py` script to test package installation
- Updated `.gitignore` to include build artifacts
- Updated `requirements.txt` with clear dependency organization
- Enhanced README.md with installation section
- **Custom exception hierarchy** (`exceptions.py`)
  - `NetworkSolverError` - Base exception for all solver errors
  - `InvalidProblemError` - Malformed problem definitions
  - `InfeasibleProblemError` - No feasible solution exists (tracks iterations)
  - `UnboundedProblemError` - Unbounded objective (includes diagnostic info)
  - `NumericalInstabilityError` - Numerical computation issues
  - `SolverConfigurationError` - Invalid solver parameters
  - `IterationLimitError` - Iteration limit reached (optional)
- Test suite for exception hierarchy (`tests/unit/test_exceptions.py`)

### Changed
- Package is now installable via `pip install -e .`
- No longer requires manual `PYTHONPATH` manipulation
- Dependencies automatically installed via pip
- **Replaced generic exceptions with specific custom exceptions:**
  - `ValueError` → `InvalidProblemError` (better error messages)
  - `KeyError` → `InvalidProblemError` (consistent error handling)
  - `RuntimeError` → `UnboundedProblemError` (includes diagnostic info)
- All exceptions now provide detailed, actionable error messages
- Exceptions include contextual information (arc details, iteration counts, etc.)

### Documentation
- Comprehensive installation guide with platform-specific notes
- Troubleshooting section for common installation issues
- Clear distinction between runtime and development dependencies
- Exception handling guide in README.md with examples
- Updated AGENTS.md to accurately reflect project structure

### Infrastructure
- Configured pytest, mypy, ruff, and coverage tools in pyproject.toml
- Optional dependency groups for development and performance
- Type hints fully configured for mypy checking
- **GitHub Actions CI/CD workflows:**
  - `ci.yml` - Comprehensive testing across Linux, macOS, Windows
  - Multi-job workflow: lint, typecheck, test, coverage, examples, build
  - Coverage reporting with Codecov integration
  - Artifact uploads for coverage reports and build distributions
  - `release.yml` - Automated PyPI publishing on GitHub releases
  - `dependency-review.yml` - Security scanning for dependencies
- CI badges added to README
- Workflow documentation in `.github/workflows/README.md`

## [Unreleased]

### Added
- **Dual values (node potentials) for sensitivity analysis**
  - `FlowResult.duals` field containing shadow prices for all nodes
  - Enables marginal cost analysis and sensitivity analysis
  - Dual values automatically computed and returned by solver
  - JSON serialization/deserialization support for dual values
  - Exported `build_problem()` function for programmatic problem creation
- **New test suite for dual values** (`tests/unit/test_dual_values.py`)
  - Complementary slackness verification
  - Shadow price interpretation tests
  - Sensitivity analysis validation (6 new tests)
- **New example: `sensitivity_analysis_example.py`**
  - Demonstrates shadow price interpretation
  - Shows marginal cost analysis with supply/demand changes
  - Verifies complementary slackness conditions
- Updated `solve_example.py` to display dual values

### Changed
- Enhanced `FlowResult` dataclass with comprehensive documentation
  - Added detailed docstring explaining all fields
  - Documented dual values and their interpretation
- All solution JSON files now include `duals` field

### Fixed
- Improved code quality with ruff linting
  - Fixed SIM108 (use ternary operators)
  - Fixed N806 (variable naming conventions)
  - Fixed C409 (unnecessary tuple wrappers)
  - Fixed B007 (unused loop variables)
  - Fixed B905 (missing strict parameter in zip)
- **CI/CD fixes:**
  - Added SuiteSparse installation for scikit-umfpack support
  - Invalidated pip cache to force rebuild with correct dependencies
  - Added swig installation for macOS builds
  - All platforms (Ubuntu, macOS, Windows) now build successfully

### Infrastructure
- All tests passing (190 tests total, including 6 new dual value tests)
- CI/CD pipeline fully operational across all platforms
- Code formatted and linted with ruff

### Added (Progress Logging)
- **Progress logging for long-running solves**
  - `ProgressInfo` dataclass with solver state (iteration, phase, objective, elapsed time)
  - `ProgressCallback` type alias for type-safe callback functions
  - Optional `progress_callback` parameter in `solve()` and `solve_min_cost_flow()`
  - Configurable `progress_interval` to control callback frequency (default: 100)
  - Real-time tracking of Phase 1 (feasibility) and Phase 2 (optimality)
  - Objective estimate computation during solve
- **New test suite for progress logging** (`tests/unit/test_progress_logging.py`)
  - Callback invocation verification
  - ProgressInfo field validation
  - Interval control testing
  - Phase tracking and iteration monotonicity (6 new tests)
- **New example: `progress_logging_example.py`**
  - Real-time progress bar with percentage, iterations, objective, time
  - Phase-aware formatting
  - Demonstrates custom progress formatting and monitoring

### Changed (Progress Logging)
- Extended `solve()` API with progress tracking capabilities
- Enhanced `solve_min_cost_flow()` to support progress callbacks
- Backward compatible - all progress parameters are optional

### Infrastructure (Progress Logging)
- All tests passing (196 tests total, including 6 new progress logging tests)
- Zero performance impact when progress_callback is None
- Fully type-annotated for IDE support

### Added (Solver Configuration)
- **SolverOptions for configurable solver behavior**
  - `SolverOptions` dataclass for centralized solver configuration
  - `max_iterations` - Override default iteration limit
  - `tolerance` - Numerical precision control (default: 1e-6)
  - `pricing_strategy` - Choose "devex" (default) or "dantzig" pricing
  - `block_size` - Control pricing block size for arc selection
  - `ft_update_limit` - Forrest-Tomlin refactorization frequency (default: 64)
  - Comprehensive validation with helpful error messages
- **Dantzig pricing strategy implementation**
  - Most negative reduced cost selection
  - Alternative to Devex pricing for different problem characteristics
- **Forrest-Tomlin update limit enforcement**
  - Periodic basis rebuilds for numerical stability
  - Configurable via `ft_update_limit` parameter
  - Tracking of basis updates between rebuilds
- **New test suite for SolverOptions** (`tests/unit/test_solver_options.py`)
  - Default values validation
  - Custom configuration testing
  - Invalid parameter detection
  - Pricing strategy comparison
  - Block size and FT limit verification (15 new tests)
- **New example: `solver_options_example.py`**
  - Demonstrates all configuration options
  - Shows impact of different settings on performance
  - Transportation problem with 8 configuration scenarios
  - Comparison of Devex vs Dantzig pricing

### Changed (Solver Configuration)
- `NetworkSimplex` constructor accepts optional `SolverOptions` parameter
- `solve_min_cost_flow()` accepts `SolverOptions` for full configuration control
- Tolerance now configurable via `SolverOptions` (previously fixed to problem tolerance)
- `max_iterations` parameter overrides options value for convenience
- Backward compatible - all parameters are optional with sensible defaults

### Infrastructure (Solver Configuration)
- All tests passing (211 tests total, including 15 new SolverOptions tests)
- Full type annotations for SolverOptions
- Comprehensive documentation in docstrings

### Added (Utility Functions)
- **extract_path() for flow path discovery**
  - BFS-based algorithm to find flow-carrying paths between nodes
  - Returns `FlowPath` dataclass with nodes, arcs, flow value, and total cost
  - Handles edge cases (no path exists, source equals target, invalid nodes)
  - Useful for tracing shipment routes and understanding flow patterns
- **validate_flow() for solution verification**
  - Verifies flow conservation at all nodes
  - Checks capacity and lower bound constraints
  - Returns `ValidationResult` with detailed violation information
  - Works with both directed and undirected problems (uses expanded arcs)
  - Configurable tolerance for numerical precision
- **compute_bottleneck_arcs() for capacity analysis**
  - Identifies arcs at or near capacity (default: 95% utilization threshold)
  - Returns list of `BottleneckArc` objects with utilization metrics
  - Sorted by utilization (highest first) for priority identification
  - Includes slack, cost, and capacity information
  - Excludes infinite capacity arcs
  - Enables sensitivity analysis for capacity expansion planning
- **New dataclasses for utility results**
  - `FlowPath` - Path representation with nodes, arcs, flow, cost
  - `ValidationResult` - Validation report with errors and violations
  - `BottleneckArc` - Bottleneck information with utilization metrics
- **New test suite** (`tests/unit/test_utils.py`)
  - Path extraction tests (simple, multi-hop, branching, edge cases) - 6 tests
  - Flow validation tests (valid solutions, violations, tolerance) - 5 tests
  - Bottleneck detection tests (thresholds, sorting, integration) - 7 tests
  - Total: 18 new comprehensive tests
- **New example: `utils_example.py`**
  - Demonstrates all three utility functions
  - Transportation problem with validation, path extraction, bottleneck analysis
  - Shows sensitivity analysis using bottleneck information
  - Real-world interpretation with factories and warehouses

### Changed (Utility Functions)
- All utility functions exported from main `network_solver` module
- Type-safe with full annotations for IDE support
- Comprehensive docstrings with usage examples

### Infrastructure (Utility Functions)
- All tests passing (229 tests total, including 18 new utility tests)
- Full type annotations for all utilities
- Example demonstrates practical usage patterns

### Added (Documentation)
- **Comprehensive `docs/` directory with 4 detailed guides**
  - `docs/algorithm.md` - Network simplex algorithm explanation (~550 lines)
    - Problem formulation with mathematical notation
    - Algorithm structure with Phase 1 (feasibility) and Phase 2 (optimality)
    - Data structures: spanning trees, node potentials, reduced costs
    - Pricing strategies: Devex vs Dantzig with detailed comparisons
    - Basis management with Forrest-Tomlin updates
    - Complexity analysis (theoretical and practical)
    - Implementation details: cost perturbation, cycle detection, potential computation
    - Academic references to key papers
  - `docs/api.md` - Complete API reference (~500 lines)
    - All functions with parameters, return types, and examples
    - Problem definition classes (NetworkProblem, Node, Arc)
    - Solver configuration (SolverOptions with all parameters)
    - Results and analysis (FlowResult with flows, objective, duals)
    - Utility functions (extract_path, validate_flow, compute_bottleneck_arcs)
    - Progress tracking (ProgressInfo, ProgressCallback)
    - Exception hierarchy with all 7 exception types
    - I/O functions (load_problem, save_result)
    - Type annotations and IDE support
  - `docs/examples.md` - Annotated code examples (~430 lines)
    - Basic transportation problem with output
    - Supply chain with transshipment nodes
    - Maximum flow problem (conversion to min-cost flow)
    - Minimum cost circulation with lower bounds
    - Progress monitoring with real-time callbacks
    - Sensitivity analysis using dual values
    - Solver configuration comparisons
    - Flow validation and bottleneck analysis workflows
  - `docs/benchmarks.md` - Performance characteristics (~400 lines)
    - Complexity analysis (theoretical O() bounds)
    - Benchmark problems by size (small to very large)
    - Performance characteristics by problem type and structure
    - Empirical scaling formulas and comparison tables
    - Optimization tips for 5 different scenarios
    - Comparison with other solvers (LP, OR-Tools, etc.)
    - Hardware impact analysis
    - Profiling and benchmarking code examples
    - Future optimization opportunities

### Changed (Documentation)
- Total of ~1,880 lines of production-quality documentation added
- Cross-references between documentation files
- Code examples with expected outputs
- Performance tables and complexity analysis

### Refactored (Code Quality)
- **Improved code quality in simplex.py**
  - Extracted `_update_devex_weight()` helper method to eliminate ~20 lines of duplication
  - Extracted `_is_better_candidate()` helper method for cleaner merit comparison logic
  - Reduced `_find_entering_arc_devex()` from ~68 lines to ~48 lines
  - Added clearer section comments for forward/backward direction checking
  - No functional changes - all 229 tests continue to pass
  - Improved maintainability and readability of pricing logic

### Improved (Undirected Graph Handling)
- **Enhanced undirected graph support and documentation**
  - Improved error messages in `undirected_expansion()` with detailed explanations
    - Infinite capacity error now explains why finite capacity is required
    - Custom lower bound error explains automatic transformation to -capacity
    - Error messages include node names and specific values for debugging
  - Comprehensive docstring for `undirected_expansion()` explaining transformation
    - Documents how edges {u,v} become arcs (u,v) with lower=-C, upper=C
    - Explains flow interpretation: positive = tail→head, negative = head→tail
    - Lists all requirements: finite capacity, no custom lower bounds, symmetric costs
  - Added extensive documentation in `docs/api.md` (~155 lines)
    - "Working with Undirected Graphs" section with detailed explanation
    - Transformation mechanics with examples
    - Flow interpretation guide (positive/negative/zero flows)
    - Common errors section with fixes
    - When to use undirected vs directed comparison
    - Internal transformation details
  - Enhanced README.md with "Undirected Graphs" subsection
    - Clear requirements list (finite capacity, no custom lower bounds)
    - Transformation explanation with bullet points
    - Flow interpretation guide
    - Link to comprehensive API documentation
  - New comprehensive example: `undirected_graph_example.py` (~200 lines)
    - Campus network design scenario (4 buildings, fiber optic cables)
    - Shows graph structure, internal transformation, solution interpretation
    - Demonstrates flow conservation and optimal routing
    - Explains key insights and undirected vs directed comparison
  - New comprehensive test suite: `tests/unit/test_undirected_graphs.py` (13 tests)
    - Simple chain, bidirectional flow, triangle network
    - Expansion transformation verification
    - Error handling (infinite capacity, custom lower bounds)
    - Multiple edges, transshipment nodes
    - Negative flow interpretation, capacity constraints
    - Undirected vs directed equivalence
    - Error message quality verification
  - All tests passing (242 total, +13 new undirected tests)
- **Updated documentation files**
  - Added "Undirected Graphs" section to `docs/examples.md` (~90 lines)
    - Complete working example with campus network scenario
    - Flow interpretation guide (positive/negative values)
    - Common errors section with fixes
    - When to use undirected vs directed guidance
  - Added "Undirected Graphs" subsection to `docs/algorithm.md`
    - Explains transformation in mathematical notation
    - Shows how edges become arcs with lower=-C, upper=C
    - Links to API reference for details

### Improved (Docstrings)
- **Comprehensive docstring improvements across all main modules**
  - **data.py enhancements:**
    - Node: Added examples for supply/demand/transshipment nodes, attributes documentation
    - Arc: Added examples for basic/infinite capacity/lower bound arcs, raises documentation, link to undirected graphs
    - NetworkProblem: Added directed/undirected examples, methods documentation, "See Also" links to build_problem, solve_min_cost_flow, and docs/algorithm.md
    - FlowResult: Expanded status codes documentation, added complete working example showing usage, "See Also" links
    - SolverOptions: Added detailed parameter guidance (ranges, tradeoffs), 4 configuration examples (default, high-precision, fast, stable), link to docs/benchmarks.md
  - **solver.py enhancements:**
    - solve_min_cost_flow(): Added time/space complexity analysis (O(n²m) best, O(nm log n) average), expanded examples, detailed returns/raises documentation, "See Also" links to docs
    - load_problem(): Added complexity analysis, examples, "See Also" links
    - save_result(): Added complexity analysis, examples, "See Also" links
  - **simplex.py enhancements:**
    - NetworkSimplex: Added algorithm overview (Phase 1/Phase 2), implementation details (spanning tree, node potentials, pricing strategies, Forrest-Tomlin), attributes documentation, "See Also" links
  - All docstrings now follow consistent format with:
    - Detailed parameter descriptions
    - Return value documentation
    - Raises documentation where applicable
    - Time and space complexity analysis for key functions
    - Working code examples
    - "See Also" cross-references to related functions and documentation
  - Total: ~250 lines of enhanced documentation added to docstrings
  - All tests passing (242 tests)
  - Type checking and linting passing

### Improved (Logging)
- **Comprehensive logging at appropriate levels**
  - **INFO level** - Phase transitions and solver progress:
    - "Starting network simplex solver" with problem size and configuration
    - "Phase 1: Finding initial feasible solution"
    - "Phase 1 complete" with iteration counts
    - "Phase 2: Optimizing from feasible basis"
    - "Phase 2 complete" with iteration counts
  - **DEBUG level** - Individual pivot details:
    - Entering arc selection with reduced cost and direction
    - Leaving arc selection with theta and degeneracy flag
    - Degenerate pivot detection
    - FT update limit reached notifications
  - **WARNING level** - Numerical issues:
    - Devex weights going non-finite (NaN/Inf) with clamping
    - Devex weights exceeding maximum bounds
    - Forrest-Tomlin update failures requiring basis rebuild
    - Iteration limit reached before optimality
  - **ERROR level** - Solver failures:
    - Infeasible problems (no feasible solution exists)
    - Iteration limit reached before finding feasible solution
  - All log messages include structured extra data for programmatic parsing
- **Added --verbose flag to example scripts**
  - solve_example.py: `-v` for INFO, `-vv` for DEBUG
  - solve_dimacs_example.py: `-v` for INFO, `-vv` for DEBUG
  - undirected_graph_example.py: `-v` for INFO, `-vv` for DEBUG
  - Consistent logging format across all examples
  - Logs go to stderr, normal output to stdout
- **Documentation updates**
  - README.md: Added "Verbose Output" section explaining log levels
  - docs/examples.md: Added note about --verbose flag at top of document
- **Benefits:**
  - Easy debugging with `-vv` flag to see every pivot
  - Monitor solver progress with `-v` flag
  - Production use with default (WARNING+) for quiet operation
  - Structured logging with extra fields for monitoring/analytics
- All tests passing (242 tests)
- Type checking and linting passing

### Improved (Enhanced Structured Logging)
- **Comprehensive structured logging with performance metrics**
  - **Starting solver** log includes:
    - Problem size: `nodes`, `arcs`
    - Configuration: `max_iterations`, `pricing_strategy`, `tolerance`
    - Problem characteristics: `total_supply`
  - **Phase 1 start** log includes:
    - `elapsed_ms`: Time since solver start (0.0 at start)
  - **Phase 1 complete** log includes:
    - Phase metrics: `iterations`, `total_iterations`
    - Feasibility metrics: `artificial_flow` (sum of artificial arc flows)
    - Performance: `elapsed_ms` (time since solver start)
  - **Phase 2 start** log includes:
    - `remaining_iterations` (max_iterations - total_iterations)
  - **Phase 2 complete** log includes:
    - Phase metrics: `iterations`, `total_iterations`
    - Solution quality: `objective` (preliminary objective value)
    - Performance: `elapsed_ms` (time since solver start)
  - **Solver complete** log includes:
    - Final status: `status` ("optimal", "iteration_limit", "infeasible")
    - Solution: `objective` (rounded to 12 decimals)
    - Iterations: `iterations` (total across both phases)
    - Performance: `elapsed_ms` (total solve time)
    - Basis metrics: `tree_arcs` (non-artificial tree arcs), `nonzero_flows`
    - Numerical stability: `ft_rebuilds` (Forrest-Tomlin basis rebuilds)
- **All metrics available in structured `extra` dict for:**
  - JSON logging for monitoring systems
  - Performance profiling and analysis
  - Automated testing and validation
  - Real-time dashboards
- **Example JSON output:**
  ```json
  {"level": "INFO", "logger": "network_solver.simplex", "message": "Starting network simplex solver", "nodes": 3, "arcs": 3, "max_iterations": 100, "pricing_strategy": "devex", "total_supply": 10.0, "tolerance": 1e-06}
  {"level": "INFO", "logger": "network_solver.simplex", "message": "Phase 1 complete", "iterations": 2, "total_iterations": 2, "artificial_flow": 0, "elapsed_ms": 2.23}
  {"level": "INFO", "logger": "network_solver.simplex", "message": "Phase 2 complete", "iterations": 0, "total_iterations": 2, "objective": 15.0, "elapsed_ms": 3.64}
  {"level": "INFO", "logger": "network_solver.simplex", "message": "Solver complete", "status": "optimal", "objective": 15.0, "iterations": 2, "elapsed_ms": 4.04, "tree_arcs": 2, "nonzero_flows": 2, "ft_rebuilds": 0}
  ```
- All tests passing (243 tests)
- Type checking and linting passing

### Improved (Dual Variables Documentation and Examples)
- **Enhanced sensitivity analysis example** (`examples/sensitivity_analysis_example.py`)
  - Added comprehensive production planning use case
    - Two-factory scenario with different costs and capacities
    - Decision analysis: which factory to expand based on dual values
    - Marginal value calculations for capacity expansion
  - Added capacity constraint analysis section
    - Identify bottlenecks using flow vs capacity comparison
    - Utilization percentage calculations
    - Recommendations for capacity increases
  - Added key concepts summary section
    - Dual values interpretation (shadow prices)
    - Complementary slackness explanation
    - Sensitivity analysis formulas
    - Practical applications list (production planning, logistics, pricing, bottlenecks)
  - Improved code organization with helper functions
    - `print_section_header()` for major sections
    - `print_subsection()` for subsections
    - Better visual separation and readability
  - Enhanced example output (~150 lines total)
- **Comprehensive dual variables documentation** (`docs/examples.md`)
  - Expanded "Sensitivity Analysis" section from ~40 lines to ~210 lines
  - Added "What are Dual Values?" conceptual introduction
    - Clear explanation of negative vs positive duals
    - Interpretation guide for practitioners
  - New subsections with complete working examples:
    - **Basic Example**: Marginal cost prediction with verification
    - **Complementary Slackness**: Optimality condition verification
    - **Production Planning**: Two-factory capacity expansion decision
    - **Capacity Bottleneck Identification**: Finding binding constraints
  - Added "Key Concepts" reference table
    - Dual value, reduced cost, complementary slackness formulas
    - Clear mathematical notation and meaning
  - Added "When to Use Dual Values" section
    - 6 practical use cases with descriptions
    - What-if analysis, capacity planning, pricing decisions, etc.
  - Added example output excerpt from running script
  - Cross-references to algorithm guide and API documentation
- **Enhanced README.md dual values section**
  - Expanded from basic explanation to practical examples
  - Added code showing cost prediction without re-solving
  - Added complementary slackness verification example
  - Added "Use cases for dual values" bulleted list
    - What-if analysis, capacity planning, pricing, bottlenecks, optimality
  - Better cross-references to examples and documentation
- **Benefits:**
  - Users can now understand and apply dual values for real-world decisions
  - Clear examples for production planning and capacity expansion
  - Mathematical foundations with practical interpretation
  - Complete working code that can be adapted to user problems
- All tests passing (243 tests)
- Type checking and linting passing

### Added (Incremental Resolving Example and Documentation)
- **New comprehensive example**: `examples/incremental_resolving_example.py` (~370 lines)
  - **Scenario 1: Capacity Expansion Analysis**
    - Demonstrates incremental capacity increases
    - Shows diminishing returns on expansion
    - Tracks objective improvement at each step
  - **Scenario 2: Cost Updates**
    - Fuel price increase impact analysis
    - Flow pattern comparison before/after
    - Percentage cost increase calculation
  - **Scenario 3: Demand Fluctuations**
    - Weekly demand variation handling
    - Multi-period re-solving
    - Cost progression tracking
  - **Scenario 4: Network Topology Changes**
    - Evaluate adding new direct routes
    - Calculate savings from topology changes
    - ROI analysis for infrastructure investments
  - **Scenario 5: Iterative Optimization**
    - Bottleneck identification → expand → re-solve loop
    - Demonstrates systematic network improvement
    - Shows when to stop iterating (diminishing returns)
  - Formatted output with clear sections and tables
  - Total solve time < 100ms for all 5 scenarios
- **Comprehensive documentation** in `docs/examples.md`
  - New "Incremental Resolving" section (~260 lines)
  - "Why Incremental Resolving?" explanation
    - Scenario analysis, cost sensitivity, demand forecasting
    - Network design, iterative optimization
  - 5 complete working code examples (one per scenario)
  - Best practices section:
    - Start simple, track metrics, validate incrementally
    - Use dual values for prediction
    - Consider tolerance in small changes
  - Performance notes:
    - Fast for networks <10,000 arcs (<100ms typical)
    - No warm-start support but re-solving is efficient
    - Can parallelize independent variants
  - Example output excerpts showing real results
- **README.md updates**
  - Added `incremental_resolving_example.py` to CLI examples list
  - Listed with clear description: "Scenario analysis and what-if modeling"
- **Use cases enabled**:
  - Capacity planning: "What if we expand this route?"
  - Cost sensitivity: "How do price changes affect solutions?"
  - Demand adaptation: Handle varying demand over time
  - Network design: Evaluate topology modifications
  - Iterative improvement: Systematically reduce costs
- **Benefits:**
  - Users can perform sophisticated what-if analysis
  - Clear patterns for common re-solving scenarios
  - Practical examples adaptable to real problems
  - Demonstrates efficient workflow for scenario analysis
- All tests passing (243 tests)
- Type checking and linting passing

### Added (Performance Profiling Example and Documentation)
- **New comprehensive example**: `examples/performance_profiling_example.py` (~440 lines)
  - **Scaling Analysis**
    - Profile solver performance across problem sizes (3×3 to 20×20 grids)
    - Measure solve time, iteration count, and throughput (iterations/sec)
    - Demonstrates quadratic time growth with problem size
    - Formatted table output for easy comparison
  - **Pricing Strategy Comparison**
    - Compare Devex vs Dantzig pricing on multiple problem types
    - Grid networks and bipartite (assignment) networks
    - Shows iteration counts, solve times, and speedup factors
    - Helps users choose optimal pricing strategy
  - **Solver Options Impact**
    - Test different `ft_update_limit` values (16, 32, 64, 128)
    - Test different `block_size` values (50, 100, 200)
    - Shows how configuration affects performance
    - Guidance for tuning solver parameters
  - **Problem Structure Analysis**
    - Compare sparse (grid), medium (hybrid), and dense (bipartite) networks
    - Calculate and display network density
    - Shows how structure affects iteration count and solve time
  - **Performance Summary**
    - Benchmark standard problem (10×10 grid)
    - Performance expectations by problem size
    - Optimization tips (5 recommendations)
    - When to profile (4 scenarios)
  - **Structured Logging for Profiling**
    - Demonstrates capturing metrics via structured logs
    - Shows integration with INFO-level logging
  - Helper functions for problem generation:
    - `generate_grid_network()`: 4-connected grid with source/sink
    - `generate_bipartite_network()`: Complete bipartite graph
    - `profile_problem()`: Unified profiling with timing
  - Suppresses solver logging during profiling for clean output
  - Total profiling time < 15s for all scenarios
- **Comprehensive documentation** in `docs/examples.md`
  - New "Performance Profiling" section (~260 lines)
  - "Why Profile Performance?" explanation (6 use cases)
    - Understand scaling, compare strategies, tune configuration
    - Identify bottlenecks, regression testing, capacity planning
  - Complete working code examples:
    - **Basic Profiling**: Simple time/iteration measurement
    - **Scaling Analysis**: Profile multiple problem sizes with table output
    - **Comparing Pricing Strategies**: Devex vs Dantzig with speedup calculation
    - **Configuration Tuning**: Test different solver options
    - **Problem Structure Analysis**: Compare sparse/dense/medium networks
    - **Structured Logging**: Capture metrics programmatically
  - Best practices (6 guidelines)
    - Profile representative problems, run multiple iterations
    - Isolate variables, track over time, document baselines
  - Performance expectations table:
    - Small (<100 nodes): <10ms
    - Medium (100-1000): 10-100ms
    - Large (1000-10000): 100ms-2s
    - Very large (>10000): Several seconds
  - Example output excerpts showing real profiling results
- **README.md updates**
  - Added `performance_profiling_example.py` to CLI examples list
  - Listed with clear description: "Performance analysis and benchmarking"
- **Use cases enabled**:
  - Performance benchmarking for different problem types
  - Solver configuration optimization
  - Regression testing across code versions
  - Capacity planning for production systems
  - Understanding scaling characteristics
  - Identifying performance bottlenecks
- **Benefits:**
  - Users can optimize solver configuration for their workloads
  - Clear guidance on what to expect performance-wise
  - Systematic approach to performance analysis
  - Helps identify when performance is abnormal
  - Enables data-driven configuration decisions
- All tests passing (243 tests)
- Type checking and linting passing

### Added (Jupyter Notebook Tutorial)
- **Optional dependency group for tutorial support**
  - New `tutorial` optional dependency group in pyproject.toml
  - Includes jupyter>=1.0.0, matplotlib>=3.5.0, networkx>=3.0
  - Install with: `pip install -e ".[tutorial]"`
  - Updated `all` group to include tutorial dependencies
- **Interactive Jupyter notebook tutorial**: `tutorials/network_flow_tutorial.ipynb`
  - **Installation and Setup** - Quick start with package installation
  - **First Network Flow Problem** - Transportation problem walkthrough
    - Define nodes (factories, warehouses) with supply/demand
    - Define arcs (shipping routes) with costs and capacities
    - Build and solve the problem
  - **Solving and Interpreting Results**
    - Access optimal flows, objective value, and solver status
    - Validate flow conservation at nodes
    - Interpret solution quality and iteration counts
  - **Dual Values and Sensitivity Analysis**
    - Understand shadow prices and node potentials
    - Predict cost impact of supply/demand changes
    - Verify complementary slackness conditions
  - **Maximum Flow Problem**
    - Convert max-flow to min-cost flow formulation
    - Add super-source and super-sink nodes
    - Extract maximum throughput from results
  - **Solver Configuration**
    - Customize iteration limits, tolerance, pricing strategy
    - Compare Devex vs Dantzig pricing
    - Tune performance parameters
  - **Incremental Resolving**
    - Modify and re-solve efficiently
    - Capacity expansion analysis
    - Cost update scenarios
  - **Bottleneck Analysis**
    - Identify capacity-constrained arcs
    - Calculate utilization percentages
    - Prioritize infrastructure investments
  - **Visualization** (Optional)
    - Plot network graphs with matplotlib and networkx
    - Visualize flow patterns and bottlenecks
    - Generate publication-quality diagrams
  - **Summary and Next Steps**
    - Key takeaways and concepts learned
    - Links to comprehensive documentation
    - Suggested learning paths
  - Total: 22 cells (12 markdown, 10 code)
  - All code cells are executable and self-contained
  - Generated programmatically via `tutorials/create_tutorial.py`
- **Documentation updates**
  - Added link to notebook in README.md Documentation section
  - Added prominent callout in `docs/examples.md` for new users
  - Positioned notebook as starting point for interactive learning
- **Use cases enabled**:
  - Interactive learning environment for beginners
  - Hands-on experimentation with immediate feedback
  - Quick reference for common workflows
  - Teaching material for courses and workshops
  - Rapid prototyping and exploration
- **Benefits:**
  - Lower barrier to entry for new users
  - Visual and interactive learning experience
  - All examples executable without setup
  - Self-contained tutorial covering all major features
  - Easy to customize and extend for specific use cases
- Notebook structure generated by Python script for maintainability
- All 243 tests continue to pass

### Added (NetworkX Comparison)
- **Comprehensive NetworkX comparison example**: `examples/networkx_comparison_example.py` (~580 lines)
  - **API Comparison**
    - Side-by-side code examples showing both libraries
    - Sign convention differences (supply/demand representation)
    - Return format comparison (FlowResult vs nested dicts)
    - Cost calculation differences
  - **Feature Comparison**
    - Detailed feature matrix comparing capabilities
    - Dual values availability (network_solver ✓, NetworkX ✗)
    - Solver configuration options (network_solver ✓, NetworkX ✗)
    - Lower bounds on arcs (network_solver ✓, NetworkX ✗)
    - Structured logging (network_solver ✓, NetworkX ✗)
    - Other graph algorithms (network_solver ✗, NetworkX ✓)
  - **Performance Comparison**
    - Benchmark on grid networks (3×3 to 15×15)
    - Solve time comparison with speedup calculations
    - Shows network_solver typically 1.8x-3.5x faster
    - Both solvers find optimal solutions
  - **When to Use Each Library**
    - Guidance for choosing between libraries
    - Use cases for network_solver (dual values, solver control, diagnostics)
    - Use cases for NetworkX (general graph analysis, visualization, ecosystem)
    - Hybrid workflow combining both libraries
  - Helper functions for generating test problems
    - `generate_grid_network()` for network_solver format
    - `create_networkx_grid()` for NetworkX format
- **Comprehensive documentation** in `docs/examples.md`
  - New "Comparison with NetworkX" section (~170 lines)
  - API comparison with code examples
  - Feature comparison table
  - When to use each library (clear guidance)
  - Example workflow combining both libraries
  - Performance comparison results table
  - Summary highlighting strengths of each approach
- **README.md updates**
  - Added `networkx_comparison_example.py` to CLI examples list
  - Positioned after performance profiling for logical flow
- **Use cases enabled**:
  - Users can make informed choice between libraries
  - Understand API differences to avoid confusion
  - Leverage strengths of both libraries together
  - Migrate between libraries when needed
  - Choose optimal tool for specific use cases
- **Benefits:**
  - Clear positioning vs established library (NetworkX)
  - Highlights unique features (dual values, solver config)
  - Acknowledges NetworkX strengths (ecosystem, visualization)
  - Promotes interoperability and hybrid workflows
  - Helps users choose the right tool for their needs
- All 242 tests continue to pass
- Example runs successfully with both libraries

### Added (Warm-Start Support)

> **Note**: Warm-start was initially released as experimental but is now fully functional (see [Unreleased] section above for bug fixes).

- **Basis extraction and warm-starting capability**
  - New `Basis` dataclass to represent spanning tree structure
    - `tree_arcs`: Set of arcs in the spanning tree
    - `arc_flows`: Flow values for warm-start initialization
  - `FlowResult.basis`: Automatically extracted from optimal/feasible solutions
  - `solve_min_cost_flow(warm_start_basis=...)`: Reuse basis from previous solve
  - Exported `Basis` class in main API
- **Warm-start implementation in NetworkSimplex**
  - `_apply_warm_start_basis()`: Apply basis from previous solve
  - `_extract_basis()`: Extract current basis for reuse
  - Intelligent fallback to cold start if warm-start fails
  - Automatic completion of spanning tree with artificial arcs
  - Phase 1 skip when warm-start basis is already feasible
  - Structured logging for warm-start success/failure
- **Comprehensive warm-start example**: `examples/warm_start_example.py` (~540 lines)
  - **Scenario 1**: Supply/demand changes with gradual increase
  - **Scenario 2**: Cost changes (fuel price variations)
  - **Scenario 3**: Capacity expansion analysis
  - **Scenario 4**: Rolling horizon planning (sequential weeks)
  - **Scenario 5**: Cold start vs warm start performance comparison
  - Shows 2-10x speedup typical for similar problems
  - Performance tables with iteration counts and timing
- **README.md documentation**
  - New "Warm-Starting for Sequential Solves" section
  - Complete code example showing usage
  - Benefits and use cases clearly explained
  - When warm-starting works best (guidelines)
  - Added to CLI examples list
- **API enhancements**
  - Updated `solve_min_cost_flow()` signature with `warm_start_basis` parameter
  - Updated docstrings with warm-start examples
  - Type-safe with full annotations
- **Use cases enabled**:
  - Sequential optimization (rolling horizon planning)
  - Sensitivity analysis with rapid scenario evaluation
  - Real-time optimization with parameter changes
  - Interactive what-if analysis
  - Parameter tuning and calibration
- **Benefits:**
  - Typical 50-90% reduction in iterations for similar problems
  - Faster solve times for sequential problems
  - Enables real-time scenario evaluation
  - Essential for interactive optimization applications
  - Automatic basis extraction (no manual setup)
- **Implementation details**:
  - Validates basis compatibility with current problem
  - Handles missing arcs gracefully (fallback to cold start)
  - Completes spanning tree with artificial arcs as needed
  - Flow initialization respects arc capacity bounds
  - Logs warm-start success/failure with structured data
- All 242 tests continue to pass

### Planned
- PyPI publication
- Additional optimization algorithms
- C++/Cython performance extensions
